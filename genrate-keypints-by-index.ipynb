{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-26T03:07:39.464466Z","iopub.execute_input":"2023-03-26T03:07:39.465077Z","iopub.status.idle":"2023-03-26T03:07:39.471010Z","shell.execute_reply.started":"2023-03-26T03:07:39.465034Z","shell.execute_reply":"2023-03-26T03:07:39.469945Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"pip install scikit-image","metadata":{"execution":{"iopub.status.busy":"2023-03-25T07:12:10.838980Z","iopub.execute_input":"2023-03-25T07:12:10.840176Z","iopub.status.idle":"2023-03-25T07:12:20.298107Z","shell.execute_reply.started":"2023-03-25T07:12:10.840137Z","shell.execute_reply":"2023-03-25T07:12:20.296845Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (0.19.3)\nRequirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (1.21.6)\nRequirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (2.6.3)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (1.3.0)\nRequirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (9.4.0)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (2021.11.2)\nRequirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (2.25.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (23.0)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (1.7.3)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install graphviz\n","metadata":{"execution":{"iopub.status.busy":"2023-03-25T07:12:20.300103Z","iopub.execute_input":"2023-03-25T07:12:20.300462Z","iopub.status.idle":"2023-03-25T07:12:29.835024Z","shell.execute_reply.started":"2023-03-25T07:12:20.300425Z","shell.execute_reply":"2023-03-25T07:12:29.833659Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Requirement already satisfied: graphviz in /opt/conda/lib/python3.7/site-packages (0.8.4)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install dask-image","metadata":{"execution":{"iopub.status.busy":"2023-03-25T07:12:29.837261Z","iopub.execute_input":"2023-03-25T07:12:29.838023Z","iopub.status.idle":"2023-03-25T07:12:39.633366Z","shell.execute_reply.started":"2023-03-25T07:12:29.837979Z","shell.execute_reply":"2023-03-25T07:12:39.632365Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Requirement already satisfied: dask-image in /opt/conda/lib/python3.7/site-packages (2022.9.0)\nRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from dask-image) (1.7.3)\nRequirement already satisfied: dask[array]>=0.16.1 in /opt/conda/lib/python3.7/site-packages (from dask-image) (2022.2.0)\nRequirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.7/site-packages (from dask-image) (1.21.6)\nRequirement already satisfied: pims>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from dask-image) (0.6.1)\nRequirement already satisfied: partd>=0.3.10 in /opt/conda/lib/python3.7/site-packages (from dask[array]>=0.16.1->dask-image) (1.3.0)\nRequirement already satisfied: toolz>=0.8.2 in /opt/conda/lib/python3.7/site-packages (from dask[array]>=0.16.1->dask-image) (0.11.2)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.7/site-packages (from dask[array]>=0.16.1->dask-image) (6.0)\nRequirement already satisfied: fsspec>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from dask[array]>=0.16.1->dask-image) (2023.1.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from dask[array]>=0.16.1->dask-image) (23.0)\nRequirement already satisfied: cloudpickle>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from dask[array]>=0.16.1->dask-image) (2.2.1)\nRequirement already satisfied: imageio in /opt/conda/lib/python3.7/site-packages (from pims>=0.4.1->dask-image) (2.25.0)\nRequirement already satisfied: slicerator>=0.9.8 in /opt/conda/lib/python3.7/site-packages (from pims>=0.4.1->dask-image) (1.1.0)\nRequirement already satisfied: locket in /opt/conda/lib/python3.7/site-packages (from partd>=0.3.10->dask[array]>=0.16.1->dask-image) (1.0.0)\nRequirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.7/site-packages (from imageio->pims>=0.4.1->dask-image) (9.4.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"\npip install imageio[pyav]","metadata":{"execution":{"iopub.status.busy":"2023-03-25T07:12:39.636742Z","iopub.execute_input":"2023-03-25T07:12:39.637097Z","iopub.status.idle":"2023-03-25T07:12:49.305847Z","shell.execute_reply.started":"2023-03-25T07:12:39.637046Z","shell.execute_reply":"2023-03-25T07:12:49.304186Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Requirement already satisfied: imageio[pyav] in /opt/conda/lib/python3.7/site-packages (2.25.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from imageio[pyav]) (1.21.6)\nRequirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.7/site-packages (from imageio[pyav]) (9.4.0)\nRequirement already satisfied: av in /opt/conda/lib/python3.7/site-packages (from imageio[pyav]) (10.0.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"#In console run following:\n#pip install scikit-image\n#pip install graphviz\n#pip install dask-image\n#pip install imageio[pyav]\nimport dask\nimport matplotlib\nimport numpy\nimport dask_image.imread\nimport dask_image.ndfilters\nimport dask_image.ndmeasure\nimport dask.array as da\nimport glob\nimport re\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2023-03-25T07:12:49.307696Z","iopub.execute_input":"2023-03-25T07:12:49.308025Z","iopub.status.idle":"2023-03-25T07:12:49.317856Z","shell.execute_reply.started":"2023-03-25T07:12:49.307993Z","shell.execute_reply":"2023-03-25T07:12:49.316359Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"labels = []\ninclude50labels = ['Bird','Black','Car','Dog','Fall','Father','Good Morning', 'Red','Summer','White','loud','quiet','happy','long','short','big large', 'small little','hot', 'new','dry','good','Cow','Hat', 'T-Shirt', 'Shoes', 'Monday', 'Year', 'Time', 'Fan', 'Cell phone', 'Hello', 'Thank you', 'Window', 'Pen', 'Paint', 'Teacher', 'Priest', 'train ticket', 'Brother', 'Boy', ' Girl', ' Bank', 'I', 'it','you', 'Election', 'Death', 'Court', 'House', 'Store or Shop']\n","metadata":{"execution":{"iopub.status.busy":"2023-03-25T07:12:49.320036Z","iopub.execute_input":"2023-03-25T07:12:49.320532Z","iopub.status.idle":"2023-03-25T07:12:49.332670Z","shell.execute_reply.started":"2023-03-25T07:12:49.320494Z","shell.execute_reply":"2023-03-25T07:12:49.331620Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def return_label(dirname):\n    return re.sub('\\d+. ','',dirname)\ndatasets = ['include-50','include-50-2']\nfor dataset in datasets:\n    os.chdir(\"/kaggle/input/{dataset_name}\".format(dataset_name = dataset))\n    root_dir_list = os.listdir()\n    for root_dir in root_dir_list:\n        os.chdir(os.path.join(os.getcwd(),root_dir))\n        dir_list = os.listdir()\n        for dir in dir_list:\n            os.chdir(os.path.join(os.getcwd(),dir))\n            n = len(os.listdir())\n            label = return_label(dir)\n            for i in range(n):\n                labels.append(label)\n            os.chdir('../')\n        os.chdir('../')","metadata":{"execution":{"iopub.status.busy":"2023-03-25T07:12:49.333867Z","iopub.execute_input":"2023-03-25T07:12:49.335325Z","iopub.status.idle":"2023-03-25T07:12:50.474548Z","shell.execute_reply.started":"2023-03-25T07:12:49.335286Z","shell.execute_reply":"2023-03-25T07:12:50.473501Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"extra_labels= { 'Bird':4,'Bank':1, 'Store or Shop':1,'Court':2}\ndef insert_extra_labels(labels, extra_labels):\n    for extra_label in extra_labels:\n        index = labels.index(extra_label)\n        for i in range(extra_labels[extra_label]):\n            labels.insert(index,extra_label)\n    return labels","metadata":{"execution":{"iopub.status.busy":"2023-03-25T07:12:50.477167Z","iopub.execute_input":"2023-03-25T07:12:50.478805Z","iopub.status.idle":"2023-03-25T07:12:50.484655Z","shell.execute_reply.started":"2023-03-25T07:12:50.478774Z","shell.execute_reply":"2023-03-25T07:12:50.483276Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"labels = insert_extra_labels(labels,extra_labels)","metadata":{"execution":{"iopub.status.busy":"2023-03-25T07:12:50.487045Z","iopub.execute_input":"2023-03-25T07:12:50.487837Z","iopub.status.idle":"2023-03-25T07:12:50.495681Z","shell.execute_reply.started":"2023-03-25T07:12:50.487799Z","shell.execute_reply":"2023-03-25T07:12:50.494668Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"len(labels)","metadata":{"execution":{"iopub.status.busy":"2023-03-25T07:12:50.497543Z","iopub.execute_input":"2023-03-25T07:12:50.498285Z","iopub.status.idle":"2023-03-25T07:12:50.509548Z","shell.execute_reply.started":"2023-03-25T07:12:50.498248Z","shell.execute_reply":"2023-03-25T07:12:50.508448Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"1146"},"metadata":{}}]},{"cell_type":"code","source":"video_frames = []\ndatasets = ['include-50','include-50-2']\nfor dataset in datasets:\n    for root,_,filenames in os.walk(\"/kaggle/input/{dataset_name}\".format(dataset_name = dataset)):\n        for filename in filenames:\n            #print(os.path.join(root,filename))\n            file_path = os.path.join(root,filename)\n            x = dask_image.imread.imread(file_path)\n            video_frames.append(x)","metadata":{"execution":{"iopub.status.busy":"2023-03-25T07:12:50.511173Z","iopub.execute_input":"2023-03-25T07:12:50.511586Z","iopub.status.idle":"2023-03-25T07:14:24.264008Z","shell.execute_reply.started":"2023-03-25T07:12:50.511552Z","shell.execute_reply":"2023-03-25T07:14:24.263009Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"len(video_frames)","metadata":{"execution":{"iopub.status.busy":"2023-03-25T07:14:24.265268Z","iopub.execute_input":"2023-03-25T07:14:24.265604Z","iopub.status.idle":"2023-03-25T07:14:24.276444Z","shell.execute_reply.started":"2023-03-25T07:14:24.265568Z","shell.execute_reply":"2023-03-25T07:14:24.275382Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"1146"},"metadata":{}}]},{"cell_type":"code","source":"%cd /kaggle/working\n%ls","metadata":{"execution":{"iopub.status.busy":"2023-03-25T07:14:24.283029Z","iopub.execute_input":"2023-03-25T07:14:24.283328Z","iopub.status.idle":"2023-03-25T07:14:25.277502Z","shell.execute_reply.started":"2023-03-25T07:14:24.283302Z","shell.execute_reply":"2023-03-25T07:14:25.276285Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"/kaggle/working\nVideo_keypoints_onethousandeight.csv\nVideo_keypoints_onethousandfifteen.csv\nVideo_keypoints_onethousandone.csv\nVideo_keypoints_onethousandtwenty.csv\nVideo_keypoints_onethousandtwentyfive.csv\n__notebook_source__.ipynb\n\u001b[0m\u001b[01;34mpytorch-openpose\u001b[0m/\nstate.db\n","output_type":"stream"}]},{"cell_type":"code","source":"rm -r -d pytorch-openpose\n","metadata":{"execution":{"iopub.status.busy":"2023-03-25T07:16:16.741475Z","iopub.execute_input":"2023-03-25T07:16:16.741869Z","iopub.status.idle":"2023-03-25T07:16:17.783884Z","shell.execute_reply.started":"2023-03-25T07:16:16.741837Z","shell.execute_reply":"2023-03-25T07:16:17.782460Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"ls","metadata":{"execution":{"iopub.status.busy":"2023-03-25T07:40:54.021771Z","iopub.execute_input":"2023-03-25T07:40:54.022820Z","iopub.status.idle":"2023-03-25T07:40:54.993307Z","shell.execute_reply.started":"2023-03-25T07:40:54.022759Z","shell.execute_reply":"2023-03-25T07:40:54.992124Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Video_keypoints_onethousandeight.csv\nVideo_keypoints_onethousandfifteen.csv\nVideo_keypoints_onethousandone.csv\nVideo_keypoints_onethousandtwenty.csv\nVideo_keypoints_onethousandtwentyfive.csv\n__notebook_source__.ipynb\nstate.db\n","output_type":"stream"}]},{"cell_type":"code","source":"\n!git clone https://github.com/Hzzone/pytorch-openpose\n%cd pytorch-openpose","metadata":{"execution":{"iopub.status.busy":"2023-03-25T07:40:58.233188Z","iopub.execute_input":"2023-03-25T07:40:58.234269Z","iopub.status.idle":"2023-03-25T07:41:00.527910Z","shell.execute_reply.started":"2023-03-25T07:40:58.234223Z","shell.execute_reply":"2023-03-25T07:41:00.526678Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Cloning into 'pytorch-openpose'...\nremote: Enumerating objects: 154, done.\u001b[K\nremote: Counting objects: 100% (154/154), done.\u001b[K\nremote: Compressing objects: 100% (85/85), done.\u001b[K\nremote: Total 154 (delta 69), reused 152 (delta 67), pack-reused 0\u001b[K\nReceiving objects: 100% (154/154), 20.18 MiB | 32.96 MiB/s, done.\nResolving deltas: 100% (69/69), done.\n/kaggle/working/pytorch-openpose\n","output_type":"stream"}]},{"cell_type":"code","source":"# import sys\n# sys.path.append(os.path.dirname(os.path.join(os.getcwd(),\"src\")))","metadata":{"execution":{"iopub.status.busy":"2023-03-25T07:14:25.292579Z","iopub.status.idle":"2023-03-25T07:14:25.293518Z","shell.execute_reply.started":"2023-03-25T07:14:25.293246Z","shell.execute_reply":"2023-03-25T07:14:25.293274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport copy\nfrom src import model\nfrom src import util\nfrom src.body import Body\nfrom src.hand import Hand\n","metadata":{"execution":{"iopub.status.busy":"2023-03-25T07:41:05.831485Z","iopub.execute_input":"2023-03-25T07:41:05.832328Z","iopub.status.idle":"2023-03-25T07:41:08.875514Z","shell.execute_reply.started":"2023-03-25T07:41:05.832284Z","shell.execute_reply":"2023-03-25T07:41:08.874491Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"\n!cp /kaggle/input/openpose-pretrained-models/body_pose_model.pth model\n!cp /kaggle/input/openpose-pretrained-models/hand_pose_model.pth model\n","metadata":{"execution":{"iopub.status.busy":"2023-03-25T07:41:09.266478Z","iopub.execute_input":"2023-03-25T07:41:09.267165Z","iopub.status.idle":"2023-03-25T07:41:17.725968Z","shell.execute_reply.started":"2023-03-25T07:41:09.267124Z","shell.execute_reply":"2023-03-25T07:41:17.724536Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"\nbody_estimation = Body('model/body_pose_model.pth')\nhand_estimation = Hand('model/hand_pose_model.pth')","metadata":{"execution":{"iopub.status.busy":"2023-03-25T07:41:17.728993Z","iopub.execute_input":"2023-03-25T07:41:17.729846Z","iopub.status.idle":"2023-03-25T07:41:22.400250Z","shell.execute_reply.started":"2023-03-25T07:41:17.729802Z","shell.execute_reply":"2023-03-25T07:41:22.399140Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def get_all_hand_peaks(hands_list,oriImg):\n    all_hand_peaks = []\n    for x, y, w, is_left in hands_list:\n        peaks = hand_estimation(oriImg[y:y+w, x:x+w, :]) #pretrained model, last layer: convolution_param-> num_output: 22, 21 Keypoints\n        #peaks is coordinates wrt x,y top left.\n        #adjust coordinates of keypoints\n        peaks[:, 0] = np.where(peaks[:, 0]==0, peaks[:, 0], peaks[:, 0]+x)\n        peaks[:, 1] = np.where(peaks[:, 1]==0, peaks[:, 1], peaks[:, 1]+y) \n        all_hand_peaks.append(peaks)\n    return all_hand_peaks\ndef generate_hand_keypoints_for_one_video(video):\n    vdo_keypoints = []\n    Num_of_frames = len(video)\n    for f in range(Num_of_frames):\n        try:\n            oriImg = np.array(video[f])\n        except:\n            continue\n        if(oriImg is None):\n            continue\n        candidate, subset = body_estimation(oriImg)\n        canvas = copy.deepcopy(oriImg)\n        hands_list = util.handDetect(candidate, subset, oriImg)\n        all_hand_peaks = get_all_hand_peaks(hands_list,oriImg)\n        vdo_keypoints.append(all_hand_peaks)\n    return vdo_keypoints\nvdo_keypoints_list = []\ndef generate_hand_keypoints_for_multiple_video(video_list,start_range, end_range):\n    #(start_range, last_range], including start and excluding last.\n    for i in range(start_range, end_range):\n        print(i)\n        vdo_keypoints_list.append(generate_hand_keypoints_for_one_video(video_list[i]))\n","metadata":{"execution":{"iopub.status.busy":"2023-03-25T07:41:22.402257Z","iopub.execute_input":"2023-03-25T07:41:22.402623Z","iopub.status.idle":"2023-03-25T07:41:22.413530Z","shell.execute_reply.started":"2023-03-25T07:41:22.402592Z","shell.execute_reply":"2023-03-25T07:41:22.412426Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"len(vdo_keypoints_list)\n#num_of_vdosxnum_of_framesx2_handsx21_keypointsx2_cordinate(x,y)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-25T12:15:51.308743Z","iopub.execute_input":"2023-03-25T12:15:51.309737Z","iopub.status.idle":"2023-03-25T12:15:51.316949Z","shell.execute_reply.started":"2023-03-25T12:15:51.309697Z","shell.execute_reply":"2023-03-25T12:15:51.315773Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"#if vdo_keypoints contains keypoints from ur last run, please make sure u select appropriate range\n#df = pd.DataFrame({'Label':labels[1015:1020],'Keypoints':vdo_keypoints_list})","metadata":{"execution":{"iopub.status.busy":"2023-03-25T07:14:25.307235Z","iopub.status.idle":"2023-03-25T07:14:25.308083Z","shell.execute_reply.started":"2023-03-25T07:14:25.307817Z","shell.execute_reply":"2023-03-25T07:14:25.307843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from IPython.display import FileLink\n# FileLink(r'Video_keypoints_five.csv')","metadata":{"execution":{"iopub.status.busy":"2023-03-25T07:14:25.309563Z","iopub.status.idle":"2023-03-25T07:14:25.310406Z","shell.execute_reply.started":"2023-03-25T07:14:25.310115Z","shell.execute_reply":"2023-03-25T07:14:25.310149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vdo_keypoints_list = []","metadata":{"execution":{"iopub.status.busy":"2023-03-25T12:15:48.305972Z","iopub.execute_input":"2023-03-25T12:15:48.306371Z","iopub.status.idle":"2023-03-25T12:15:48.312612Z","shell.execute_reply.started":"2023-03-25T12:15:48.306337Z","shell.execute_reply":"2023-03-25T12:15:48.311526Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"#Start index's keypoints are created, end is not included.\n#IMPORTANT: After generatig the CSV do not forget to do vdo_keypoints_list= []\n\nstart = 1060\nend = 1070\ngenerate_hand_keypoints_for_multiple_video(video_frames, start,end)\ndf = pd.DataFrame({'Label':labels[start:end],'Keypoints':vdo_keypoints_list})\n%cd /kaggle/working\ndf.to_csv('Video_keypoints_%d_%d.csv'%(start,end))","metadata":{"execution":{"iopub.status.busy":"2023-03-25T12:15:56.588915Z","iopub.execute_input":"2023-03-25T12:15:56.590016Z","iopub.status.idle":"2023-03-25T12:59:45.944422Z","shell.execute_reply.started":"2023-03-25T12:15:56.589978Z","shell.execute_reply":"2023-03-25T12:59:45.943250Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"1055\n1056\n1057\n1058\n1059\n/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"ls\n","metadata":{"execution":{"iopub.status.busy":"2023-03-26T03:07:56.472952Z","iopub.execute_input":"2023-03-26T03:07:56.473668Z","iopub.status.idle":"2023-03-26T03:07:57.452049Z","shell.execute_reply.started":"2023-03-26T03:07:56.473628Z","shell.execute_reply":"2023-03-26T03:07:57.450549Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Video_keypoints_onethousandeight.csv\nVideo_keypoints_onethousandfifteen.csv\nVideo_keypoints_onethousandfiftyfive.csv\nVideo_keypoints_onethousandfortyfive.csv\nVideo_keypoints_onethousandone.csv\nVideo_keypoints_onethousandthirty.csv\nVideo_keypoints_onethousandthirtyfive.csv\nVideo_keypoints_onethousandtwenty.csv\nVideo_keypoints_onethousandtwentyfive.csv\n__notebook_source__.ipynb\n\u001b[0m\u001b[01;34mpytorch-openpose\u001b[0m/\nstate.db\n","output_type":"stream"}]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-03-25T12:59:46.952584Z","iopub.execute_input":"2023-03-25T12:59:46.952910Z","iopub.status.idle":"2023-03-25T12:59:48.421250Z","shell.execute_reply.started":"2023-03-25T12:59:46.952877Z","shell.execute_reply":"2023-03-25T12:59:48.420105Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"              Label                                          Keypoints\n0  Race (ethnicity)  [[[[0 0], [0 0], [0 0], [0 0], [0 0], [0 0], [...\n1  Race (ethnicity)  [[[[0 0], [0 0], [0 0], [0 0], [0 0], [0 0], [...\n2  Race (ethnicity)  [[[[0 0], [0 0], [0 0], [0 0], [0 0], [1122  7...\n3  Race (ethnicity)  [[[[1053  782], [0 0], [0 0], [1028  844], [0 ...\n4  Race (ethnicity)  [[[[0 0], [0 0], [0 0], [0 0], [0 0], [0 0], [...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>Keypoints</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Race (ethnicity)</td>\n      <td>[[[[0 0], [0 0], [0 0], [0 0], [0 0], [0 0], [...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Race (ethnicity)</td>\n      <td>[[[[0 0], [0 0], [0 0], [0 0], [0 0], [0 0], [...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Race (ethnicity)</td>\n      <td>[[[[0 0], [0 0], [0 0], [0 0], [0 0], [1122  7...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Race (ethnicity)</td>\n      <td>[[[[1053  782], [0 0], [0 0], [1028  844], [0 ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Race (ethnicity)</td>\n      <td>[[[[0 0], [0 0], [0 0], [0 0], [0 0], [0 0], [...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#vdo_keypoints_list = []","metadata":{},"execution_count":null,"outputs":[]}]}