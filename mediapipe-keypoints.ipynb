{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-30T13:40:43.818914Z","iopub.execute_input":"2023-04-30T13:40:43.819333Z","iopub.status.idle":"2023-04-30T13:40:43.854492Z","shell.execute_reply.started":"2023-04-30T13:40:43.819296Z","shell.execute_reply":"2023-04-30T13:40:43.853101Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"pip install mediapipe","metadata":{"execution":{"iopub.status.busy":"2023-04-30T13:40:43.857082Z","iopub.execute_input":"2023-04-30T13:40:43.857483Z","iopub.status.idle":"2023-04-30T13:41:00.698979Z","shell.execute_reply.started":"2023-04-30T13:40:43.857444Z","shell.execute_reply":"2023-04-30T13:41:00.697390Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting mediapipe\n  Downloading mediapipe-0.9.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.0/33.0 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: protobuf<4,>=3.11 in /opt/conda/lib/python3.7/site-packages (from mediapipe) (3.20.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from mediapipe) (1.21.6)\nRequirement already satisfied: attrs>=19.1.0 in /opt/conda/lib/python3.7/site-packages (from mediapipe) (22.2.0)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from mediapipe) (1.4.0)\nRequirement already satisfied: opencv-contrib-python in /opt/conda/lib/python3.7/site-packages (from mediapipe) (4.5.4.60)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from mediapipe) (3.5.3)\nRequirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.7/site-packages (from mediapipe) (23.1.21)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mediapipe) (4.38.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mediapipe) (2.8.2)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mediapipe) (1.4.4)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mediapipe) (9.4.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mediapipe) (23.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mediapipe) (0.11.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mediapipe) (3.0.9)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->mediapipe) (4.4.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\nInstalling collected packages: mediapipe\nSuccessfully installed mediapipe-0.9.0.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import mediapipe as mp","metadata":{"execution":{"iopub.status.busy":"2023-04-30T13:41:00.701159Z","iopub.execute_input":"2023-04-30T13:41:00.701583Z","iopub.status.idle":"2023-04-30T13:41:01.024087Z","shell.execute_reply.started":"2023-04-30T13:41:00.701540Z","shell.execute_reply":"2023-04-30T13:41:01.022586Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"ls /kaggle/input/include-50/","metadata":{"execution":{"iopub.status.busy":"2023-04-30T13:41:01.027345Z","iopub.execute_input":"2023-04-30T13:41:01.028562Z","iopub.status.idle":"2023-04-30T13:41:02.150553Z","shell.execute_reply.started":"2023-04-30T13:41:01.028499Z","shell.execute_reply":"2023-04-30T13:41:02.149151Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\u001b[0m\u001b[01;34mAdjectives\u001b[0m/  \u001b[01;34mClothes\u001b[0m/        \u001b[01;34mElectronics\u001b[0m/  \u001b[01;34mHome\u001b[0m/  \u001b[01;34mMeans_of_Transportation\u001b[0m/\n\u001b[01;34mAnimals\u001b[0m/     \u001b[01;34mDays_and_Time\u001b[0m/  \u001b[01;34mGreetings\u001b[0m/    \u001b[01;34mJobs\u001b[0m/\n","output_type":"stream"}]},{"cell_type":"code","source":"ls","metadata":{"execution":{"iopub.status.busy":"2023-04-30T13:41:02.154745Z","iopub.execute_input":"2023-04-30T13:41:02.155197Z","iopub.status.idle":"2023-04-30T13:41:03.249172Z","shell.execute_reply.started":"2023-04-30T13:41:02.155150Z","shell.execute_reply":"2023-04-30T13:41:03.247727Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"__notebook_source__.ipynb\n","output_type":"stream"}]},{"cell_type":"code","source":"mkdir keypoints1","metadata":{"execution":{"iopub.status.busy":"2023-04-30T13:41:22.519588Z","iopub.execute_input":"2023-04-30T13:41:22.520000Z","iopub.status.idle":"2023-04-30T13:41:23.615963Z","shell.execute_reply.started":"2023-04-30T13:41:22.519965Z","shell.execute_reply":"2023-04-30T13:41:23.614430Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import os\nimport json\nimport multiprocessing\nimport argparse\nimport os.path\nimport cv2\nimport mediapipe as mp\nfrom tqdm.auto import tqdm\nfrom joblib import Parallel, delayed\nimport numpy as np\nimport gc\nimport warnings\n\ndef process_landmarks(landmarks):\n    x_list, y_list = [], []\n    for landmark in landmarks.landmark:\n        x_list.append(landmark.x)\n        y_list.append(landmark.y)\n    return x_list, y_list\n\n\ndef process_hand_keypoints(results):\n    hand1_x, hand1_y, hand2_x, hand2_y = [], [], [], []\n\n    if results.multi_hand_landmarks is not None:\n        if len(results.multi_hand_landmarks) > 0:\n            hand1 = results.multi_hand_landmarks[0]\n            hand1_x, hand1_y = process_landmarks(hand1)\n\n        if len(results.multi_hand_landmarks) > 1:\n            hand2 = results.multi_hand_landmarks[1]\n            hand2_x, hand2_y = process_landmarks(hand2)\n\n    return hand1_x, hand1_y, hand2_x, hand2_y\n\n\ndef process_pose_keypoints(results):\n    pose = results.pose_landmarks\n    pose_x, pose_y = process_landmarks(pose)\n    return pose_x, pose_y\n\n\ndef swap_hands(left_wrist, right_wrist, hand, input_hand):\n    left_wrist_x, left_wrist_y = left_wrist\n    right_wrist_x, right_wrist_y = right_wrist\n    hand_x, hand_y = hand\n\n    left_dist = (left_wrist_x - hand_x) ** 2 + (left_wrist_y - hand_y) ** 2\n    right_dist = (right_wrist_x - hand_x) ** 2 + (right_wrist_y - hand_y) ** 2\n\n    if left_dist < right_dist and input_hand == \"h2\":\n        return True\n\n    if right_dist < left_dist and input_hand == \"h1\":\n        return True\n\n    return False\n\n\ndef process_video(path, save_dir):\n    hands = mp.solutions.hands.Hands(\n        min_detection_confidence=0.5, min_tracking_confidence=0.5\n    )\n    pose = mp.solutions.pose.Pose(\n        min_detection_confidence=0.5, min_tracking_confidence=0.5#, upper_body_only=True\n    )\n\n    pose_points_x, pose_points_y = [], []\n    hand1_points_x, hand1_points_y = [], []\n    hand2_points_x, hand2_points_y = [], []\n\n    label = path.split(\"/\")[-2]\n    label = \"\".join([i for i in label if i.isalpha()]).lower()\n    uid = os.path.splitext(os.path.basename(path))[0]\n    uid = \"_\".join([label, uid])\n    n_frames = 0\n    if not os.path.isfile(path):\n        warnings.warn(path + \" file not found\")\n    cap = cv2.VideoCapture(path)\n    while cap.isOpened():\n        ret, image = cap.read()\n        if not ret:\n            break\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        hand_results = hands.process(image)\n        pose_results = pose.process(image)\n\n        hand1_x, hand1_y, hand2_x, hand2_y = process_hand_keypoints(hand_results)\n        pose_x, pose_y = process_pose_keypoints(pose_results)\n\n        ## Assign hands to correct positions\n        if len(hand1_x) > 0 and len(hand2_x) == 0:\n            if swap_hands(\n                left_wrist=(pose_x[15], pose_y[15]),\n                right_wrist=(pose_x[16], pose_y[16]),\n                hand=(hand1_x[0], hand1_y[0]),\n                input_hand=\"h1\",\n            ):\n                hand1_x, hand1_y, hand2_x, hand2_y = hand2_x, hand2_y, hand1_x, hand1_y\n\n        elif len(hand1_x) == 0 and len(hand2_x) > 0:\n            if swap_hands(\n                left_wrist=(pose_x[15], pose_y[15]),\n                right_wrist=(pose_x[16], pose_y[16]),\n                hand=(hand2_x[0], hand2_y[0]),\n                input_hand=\"h2\",\n            ):\n                hand1_x, hand1_y, hand2_x, hand2_y = hand2_x, hand2_y, hand1_x, hand1_y\n\n        ## Set to nan so that values can be interpolated in dataloader\n        pose_x = pose_x if pose_x else [np.nan] * 25\n        pose_y = pose_y if pose_y else [np.nan] * 25\n\n        hand1_x = hand1_x if hand1_x else [np.nan] * 21\n        hand1_y = hand1_y if hand1_y else [np.nan] * 21\n        hand2_x = hand2_x if hand2_x else [np.nan] * 21\n        hand2_y = hand2_y if hand2_y else [np.nan] * 21\n\n        pose_points_x.append(pose_x)\n        pose_points_y.append(pose_y)\n        hand1_points_x.append(hand1_x)\n        hand1_points_y.append(hand1_y)\n        hand2_points_x.append(hand2_x)\n        hand2_points_y.append(hand2_y)\n\n        n_frames += 1\n\n    cap.release()\n\n    ## Set to nan so that values can be interpolated in dataloader\n    pose_points_x = pose_points_x if pose_points_x else [[np.nan] * 25]\n    pose_points_y = pose_points_y if pose_points_y else [[np.nan] * 25]\n\n    hand1_points_x = hand1_points_x if hand1_points_x else [[np.nan] * 21]\n    hand1_points_y = hand1_points_y if hand1_points_y else [[np.nan] * 21]\n    hand2_points_x = hand2_points_x if hand2_points_x else [[np.nan] * 21]\n    hand2_points_y = hand2_points_y if hand2_points_y else [[np.nan] * 21]\n\n    save_data = {\n        \"uid\": uid,\n        \"label\": label,\n        \"pose_x\": pose_points_x,\n        \"pose_y\": pose_points_y,\n        \"hand1_x\": hand1_points_x,\n        \"hand1_y\": hand1_points_y,\n        \"hand2_x\": hand2_points_x,\n        \"hand2_y\": hand2_points_y,\n        \"n_frames\": n_frames,\n    }\n    with open(os.path.join(save_dir, f\"{uid}.json\"), \"w\") as f:\n        json.dump(save_data, f)\n\n    hands.close()\n    pose.close()\n    del hands, pose, save_data\n    gc.collect()\n\n\ndef load_file(path, include_dir):\n    with open(path, \"r\") as fp:\n        data = fp.read()\n        data = data.split(\"\\n\")\n    data = list(map(lambda x: os.path.join(include_dir, x), data))\n    return data\n\n\n# def load_train_test_val_paths(args):\n#     train_paths = load_file(\n#         f\"train_test_paths/{args.dataset}_train.txt\", args.include_dir\n#     )\n#     val_paths = load_file(f\"train_test_paths/{args.dataset}_val.txt\", args.include_dir)\n#     test_paths = load_file(\n#         f\"train_test_paths/{args.dataset}_test.txt\", args.include_dir\n#     )\n#     return train_paths, val_paths, test_paths\n\n\ndef save_keypoints(dataset, file_paths, mode, args):\n    save_dir = os.path.join(args['save_direc'], f\"{dataset}_keypoints\")\n    if not os.path.exists(save_dir):\n        os.mkdir(save_dir)\n\n    Parallel(n_jobs=n_cores, backend=\"multiprocessing\")(\n        delayed(process_video)(path, save_dir)\n        for path in tqdm(file_paths, desc=f\"processing videos\")\n    )\n\n\n#if __name__ == \"__main__\":\n#    parser = argparse.ArgumentParser(description=\"Generate keypoints from Mediapipe\")\nargs = {\n    'include_dir':'/kaggle/input/include-50/',\n    #/kaggle/input/include-50-2/\n    'save_direc':'/kaggle/working/keypoints1/',\n    'dataset':'include50'\n}\n\n# parser.add_argument(\n#         \"--include_dir\",\n#         default=\"\",\n#         type=str,\n#         required=True,\n#         help=\"path to the location of INCLUDE/INCLUDE50 videos\",\n#     )\n#     parser.add_argument(\n#         \"--save_dir\",\n#         default=\"\",\n#         type=str,\n#         required=True,\n#         help=\"location to output json file\",\n#     )\n#     parser.add_argument(\n#         \"--dataset\", default=\"include\", type=str, help=\"options: include or include50\"\n#     )\n#     args = parser.parse_args()\n\nn_cores = multiprocessing.cpu_count()\n#     train_paths, val_paths, test_paths = load_train_test_val_paths(args)\n\n#     save_keypoints('include50', val_paths, \"val\")\n#     save_keypoints('include50', test_paths, \"test\")\nsave_keypoints('include50', args['include_dir'], \"train\", args)\nsave_keypoints('include50', '/kaggle/input/include-50-2/', \"train\",args)","metadata":{"execution":{"iopub.status.busy":"2023-04-30T13:41:30.334169Z","iopub.execute_input":"2023-04-30T13:41:30.334658Z","iopub.status.idle":"2023-04-30T13:41:32.706728Z","shell.execute_reply.started":"2023-04-30T13:41:30.334614Z","shell.execute_reply":"2023-04-30T13:41:32.704606Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"processing videos:   0%|          | 0/25 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88ffba61d15d498d87aa365ee4415da4"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:78: UserWarning: / file not found\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n[ERROR:0] global /tmp/pip-req-build-jpmv6t9_/opencv/modules/videoio/src/cap.cpp (164) open VIDEOIO(CV_IMAGES): raised OpenCV exception:\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/videoio/src/cap_images.cpp:253: error: (-5:Bad argument) CAP_IMAGES: can't find starting number (in the name of file): / in function 'icvExtractPattern'\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:78: UserWarning: / file not found\n[ERROR:0] global /tmp/pip-req-build-jpmv6t9_/opencv/modules/videoio/src/cap.cpp (164) open VIDEOIO(CV_IMAGES): raised OpenCV exception:\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/videoio/src/cap_images.cpp:253: error: (-5:Bad argument) CAP_IMAGES: can't find starting number (in the name of file): / in function 'icvExtractPattern'\n\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)","\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 289, in __call__\n    for func, args, kwargs in self.items]\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 289, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/tmp/ipykernel_27/249474427.py\", line 72, in process_video\n    label = path.split(\"/\")[-2]\nIndexError: list index out of range\n\"\"\"","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/249474427.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;31m#     save_keypoints('include50', val_paths, \"val\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;31m#     save_keypoints('include50', test_paths, \"test\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m \u001b[0msave_keypoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'include50'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'include_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0msave_keypoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'include50'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/kaggle/input/include-50-2/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/249474427.py\u001b[0m in \u001b[0;36msave_keypoints\u001b[0;34m(dataset, file_paths, mode, args)\u001b[0m\n\u001b[1;32m    184\u001b[0m     Parallel(n_jobs=n_cores, backend=\"multiprocessing\")(\n\u001b[1;32m    185\u001b[0m         \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_video\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"processing videos\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m     )\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"],"ename":"IndexError","evalue":"list index out of range","output_type":"error"}]},{"cell_type":"markdown","source":"To DO\n1. Understand ai4bharat mediapipe code\n2. debug it\n\ndone 3. use mediapipe from scratch for 1 vdo","metadata":{}},{"cell_type":"code","source":"#ignore this box, this was me trying to understand opencv\ncap = cv2.VideoCapture('/kaggle/input/include-50/Adjectives/1. loud/MVI_5177.MOV')\nwhile cap.isOpened():\n    ret, image = cap.read()\n    if not ret:\n        break\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-30T13:41:03.670753Z","iopub.status.idle":"2023-04-30T13:41:03.671228Z","shell.execute_reply.started":"2023-04-30T13:41:03.671008Z","shell.execute_reply":"2023-04-30T13:41:03.671032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To DO for group:\n1. make a dataframe, like previous one. hand1x,hand1y, hand2x, hand2y, label, n_frames.\n2. instead of processing all frames, only select mid 30? or 40? and then process them.\n3. write a function to extract keypoints, for that we have to understand the structure of hand_landmarker_result","metadata":{}},{"cell_type":"code","source":"import mediapipe as mp\n\nBaseOptions = mp.tasks.BaseOptions\nHandLandmarker = mp.tasks.vision.HandLandmarker\nHandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions\nVisionRunningMode = mp.tasks.vision.RunningMode\n\n# Create a hand landmarker instance with the video mode:\noptions = HandLandmarkerOptions(\n    base_options=BaseOptions(model_asset_path='/kaggle/input/hand-landmark/hand_landmarker.task'),\n    running_mode=VisionRunningMode.VIDEO)\n\nwith HandLandmarker.create_from_options(options) as landmarker:\n    \n  # The landmarker is initialized. Use it here.\n  # ...\n    # Use OpenCV’s VideoCapture to load the input video.\n    cap = cv2.VideoCapture('/kaggle/input/include-50/Adjectives/1. loud/MVI_5177.MOV')\n    video_framerate = cap.get(cv2.CAP_PROP_FPS)\n    vdo_keypoints = []\n    \n    while cap.isOpened():\n        ret, image = cap.read() #read returns if frame_exits, current_frame\n        if not ret:\n            break\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #when we load, its in blue green red, we convert it to RGB\n    # Load the frame rate of the video using OpenCV’s CV_CAP_PROP_FPS\n    # You’ll need it to calculate the timestamp for each frame.\n    # Loop through each frame in the video using VideoCapture#read()\n    # Convert the frame received from OpenCV to a MediaPipe’s Image object.\n        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image)\n        # Perform hand landmarks detection on the provided single image.\n        # The hand landmarker must be created with the video mode.\n        frame_timestamp_ms = int(cap.get(cv2.CAP_PROP_POS_MSEC))\n        print(type(frame_timestamp_ms))\n        #case CV_FFMPEG_CAP_PROP_POS_MSEC:\n        #return 1000.0*(double)frame_number/get_fps();\n        hand_landmarker_result = landmarker.detect_for_video(mp_image, frame_timestamp_ms)\n        print(hand_landmarker_result)\n        hand1_x,hand1_y, hand2_x, hand2_y = process_hand_landmarker_result(hand_landmarker_result) #\n        \n        #process the output.\n        \n        \n        \n        cap.release()\n        \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-04-30T13:42:45.481066Z","iopub.execute_input":"2023-04-30T13:42:45.482635Z","iopub.status.idle":"2023-04-30T13:42:45.701103Z","shell.execute_reply.started":"2023-04-30T13:42:45.482565Z","shell.execute_reply":"2023-04-30T13:42:45.699187Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"25.0\n<class 'int'>\nHandLandmarkerResult(handedness=[[Category(index=1, score=0.9402497410774231, display_name='Right', category_name='Right')]], hand_landmarks=[[NormalizedLandmark(x=0.6061415672302246, y=0.7957913279533386, z=1.194399459336637e-07, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.5919004678726196, y=0.810642421245575, z=-0.0041010091081261635, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.5862265229225159, y=0.8386191129684448, z=-0.00514757726341486, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.5840981602668762, y=0.8651171326637268, z=-0.0048139579594135284, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.583078145980835, y=0.8845532536506653, z=-0.003933663014322519, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.5981758832931519, y=0.8641141057014465, z=-0.007079826667904854, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.5916528105735779, y=0.9002236723899841, z=-0.00813490804284811, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.5855880379676819, y=0.9136541485786438, z=-0.007690135855227709, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.5804057121276855, y=0.921369194984436, z=-0.006764574907720089, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6079766154289246, y=0.865998387336731, z=-0.004612537566572428, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6023457646369934, y=0.9040529727935791, z=-0.0057408688589930534, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.5946489572525024, y=0.9157304167747498, z=-0.0048256078734993935, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.5881791710853577, y=0.9188370108604431, z=-0.0036488708574324846, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6144354343414307, y=0.8632082343101501, z=-0.0020344688091427088, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6101601719856262, y=0.8964904546737671, z=-0.002153323730453849, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6028494834899902, y=0.9077927470207214, z=-0.0014270043466240168, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.596622884273529, y=0.9114354252815247, z=-0.0006935136625543237, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.617939829826355, y=0.8579522371292114, z=0.0003022230521310121, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6166030764579773, y=0.8849121928215027, z=0.0010807852959260345, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6118630766868591, y=0.8947299718856812, z=0.002226580400019884, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6070494651794434, y=0.8968249559402466, z=0.003353453939780593, visibility=0.0, presence=0.0)]], hand_world_landmarks=[[Landmark(x=0.0001354031264781952, y=-0.05638786405324936, z=0.04831307753920555, visibility=0.0, presence=0.0), Landmark(x=-0.0204472579061985, y=-0.037365399301052094, z=0.03306834399700165, visibility=0.0, presence=0.0), Landmark(x=-0.0306948684155941, y=-0.017398076131939888, z=0.02088986150920391, visibility=0.0, presence=0.0), Landmark(x=-0.030556248500943184, y=-0.0009477399289608002, z=0.0052291275933384895, visibility=0.0, presence=0.0), Landmark(x=-0.03075431101024151, y=0.012153667397797108, z=-0.010694650001823902, visibility=0.0, presence=0.0), Landmark(x=-0.006494888570159674, y=0.002032971242442727, z=-0.00828457996249199, visibility=0.0, presence=0.0), Landmark(x=-0.015183228999376297, y=0.014901095069944859, z=-0.011591515503823757, visibility=0.0, presence=0.0), Landmark(x=-0.027484090998768806, y=0.034071020781993866, z=0.003978711552917957, visibility=0.0, presence=0.0), Landmark(x=-0.03781049698591232, y=0.047738999128341675, z=0.019584709778428078, visibility=0.0, presence=0.0), Landmark(x=0.001892321859486401, y=0.0008347670664079487, z=-0.003003905527293682, visibility=0.0, presence=0.0), Landmark(x=-0.0007222611457109451, y=0.021319257095456123, z=-0.004532496444880962, visibility=0.0, presence=0.0), Landmark(x=-0.010737475007772446, y=0.04125937074422836, z=0.01365724392235279, visibility=0.0, presence=0.0), Landmark(x=-0.02646825462579727, y=0.05725303664803505, z=0.03321485593914986, visibility=0.0, presence=0.0), Landmark(x=0.005321582779288292, y=0.0002934139920398593, z=0.004524284973740578, visibility=0.0, presence=0.0), Landmark(x=0.005880868993699551, y=0.01535433903336525, z=0.009798540733754635, visibility=0.0, presence=0.0), Landmark(x=-0.0016303854063153267, y=0.034180574119091034, z=0.02474578656256199, visibility=0.0, presence=0.0), Landmark(x=-0.0163614209741354, y=0.046236373484134674, z=0.042154647409915924, visibility=0.0, presence=0.0), Landmark(x=0.010867711156606674, y=-0.004789487458765507, z=0.0204328540712595, visibility=0.0, presence=0.0), Landmark(x=0.013241663575172424, y=0.00684369495138526, z=0.024176031351089478, visibility=0.0, presence=0.0), Landmark(x=0.010124018415808678, y=0.020132964476943016, z=0.03319269046187401, visibility=0.0, presence=0.0), Landmark(x=-0.0008873594924807549, y=0.027617450803518295, z=0.040588073432445526, visibility=0.0, presence=0.0)]])\n","output_type":"stream"}]},{"cell_type":"code","source":"print(type(hand_landmarker_result.hand_landmarks))","metadata":{"execution":{"iopub.status.busy":"2023-04-30T13:45:43.822634Z","iopub.execute_input":"2023-04-30T13:45:43.823083Z","iopub.status.idle":"2023-04-30T13:45:43.830613Z","shell.execute_reply.started":"2023-04-30T13:45:43.823044Z","shell.execute_reply":"2023-04-30T13:45:43.829308Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"<class 'list'>\n","output_type":"stream"}]},{"cell_type":"code","source":"print(type(hand_landmarker_result.handedness))","metadata":{"execution":{"iopub.status.busy":"2023-04-30T13:46:11.351184Z","iopub.execute_input":"2023-04-30T13:46:11.351687Z","iopub.status.idle":"2023-04-30T13:46:11.359532Z","shell.execute_reply.started":"2023-04-30T13:46:11.351644Z","shell.execute_reply":"2023-04-30T13:46:11.357848Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"<class 'list'>\n","output_type":"stream"}]},{"cell_type":"code","source":"print(type(hand_landmarker_result.hand_world_landmarks))","metadata":{"execution":{"iopub.status.busy":"2023-04-30T14:01:48.185388Z","iopub.execute_input":"2023-04-30T14:01:48.185835Z","iopub.status.idle":"2023-04-30T14:01:48.192010Z","shell.execute_reply.started":"2023-04-30T14:01:48.185797Z","shell.execute_reply":"2023-04-30T14:01:48.190516Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"<class 'list'>\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(hand_landmarker_result.hand_world_landmarks[0]))","metadata":{"execution":{"iopub.status.busy":"2023-04-30T14:02:09.233968Z","iopub.execute_input":"2023-04-30T14:02:09.234488Z","iopub.status.idle":"2023-04-30T14:02:09.242256Z","shell.execute_reply.started":"2023-04-30T14:02:09.234444Z","shell.execute_reply":"2023-04-30T14:02:09.240354Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"21\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(hand_landmarker_result.hand_landmarks[0]))","metadata":{"execution":{"iopub.status.busy":"2023-04-30T14:00:52.861346Z","iopub.execute_input":"2023-04-30T14:00:52.862290Z","iopub.status.idle":"2023-04-30T14:00:52.869142Z","shell.execute_reply.started":"2023-04-30T14:00:52.862222Z","shell.execute_reply":"2023-04-30T14:00:52.867780Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"21\n","output_type":"stream"}]},{"cell_type":"code","source":"hand_landmarker_result.hand_landmarks[0]","metadata":{"execution":{"iopub.status.busy":"2023-04-30T13:47:45.073337Z","iopub.execute_input":"2023-04-30T13:47:45.073789Z","iopub.status.idle":"2023-04-30T13:47:45.083010Z","shell.execute_reply.started":"2023-04-30T13:47:45.073748Z","shell.execute_reply":"2023-04-30T13:47:45.081596Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"[NormalizedLandmark(x=0.6061415672302246, y=0.7957913279533386, z=1.194399459336637e-07, visibility=0.0, presence=0.0),\n NormalizedLandmark(x=0.5919004678726196, y=0.810642421245575, z=-0.0041010091081261635, visibility=0.0, presence=0.0),\n NormalizedLandmark(x=0.5862265229225159, y=0.8386191129684448, z=-0.00514757726341486, visibility=0.0, presence=0.0),\n NormalizedLandmark(x=0.5840981602668762, y=0.8651171326637268, z=-0.0048139579594135284, visibility=0.0, presence=0.0),\n NormalizedLandmark(x=0.583078145980835, y=0.8845532536506653, z=-0.003933663014322519, visibility=0.0, presence=0.0),\n NormalizedLandmark(x=0.5981758832931519, y=0.8641141057014465, z=-0.007079826667904854, visibility=0.0, presence=0.0),\n NormalizedLandmark(x=0.5916528105735779, y=0.9002236723899841, z=-0.00813490804284811, visibility=0.0, presence=0.0),\n NormalizedLandmark(x=0.5855880379676819, y=0.9136541485786438, z=-0.007690135855227709, visibility=0.0, presence=0.0),\n NormalizedLandmark(x=0.5804057121276855, y=0.921369194984436, z=-0.006764574907720089, visibility=0.0, presence=0.0),\n NormalizedLandmark(x=0.6079766154289246, y=0.865998387336731, z=-0.004612537566572428, visibility=0.0, presence=0.0),\n NormalizedLandmark(x=0.6023457646369934, y=0.9040529727935791, z=-0.0057408688589930534, visibility=0.0, presence=0.0),\n NormalizedLandmark(x=0.5946489572525024, y=0.9157304167747498, z=-0.0048256078734993935, visibility=0.0, presence=0.0),\n NormalizedLandmark(x=0.5881791710853577, y=0.9188370108604431, z=-0.0036488708574324846, visibility=0.0, presence=0.0),\n NormalizedLandmark(x=0.6144354343414307, y=0.8632082343101501, z=-0.0020344688091427088, visibility=0.0, presence=0.0),\n NormalizedLandmark(x=0.6101601719856262, y=0.8964904546737671, z=-0.002153323730453849, visibility=0.0, presence=0.0),\n NormalizedLandmark(x=0.6028494834899902, y=0.9077927470207214, z=-0.0014270043466240168, visibility=0.0, presence=0.0),\n NormalizedLandmark(x=0.596622884273529, y=0.9114354252815247, z=-0.0006935136625543237, visibility=0.0, presence=0.0),\n NormalizedLandmark(x=0.617939829826355, y=0.8579522371292114, z=0.0003022230521310121, visibility=0.0, presence=0.0),\n NormalizedLandmark(x=0.6166030764579773, y=0.8849121928215027, z=0.0010807852959260345, visibility=0.0, presence=0.0),\n NormalizedLandmark(x=0.6118630766868591, y=0.8947299718856812, z=0.002226580400019884, visibility=0.0, presence=0.0),\n NormalizedLandmark(x=0.6070494651794434, y=0.8968249559402466, z=0.003353453939780593, visibility=0.0, presence=0.0)]"},"metadata":{}}]},{"cell_type":"code","source":"hand_landmarker_result.hand_world_landmarks[0]","metadata":{"execution":{"iopub.status.busy":"2023-04-30T14:06:09.686694Z","iopub.execute_input":"2023-04-30T14:06:09.687124Z","iopub.status.idle":"2023-04-30T14:06:09.696091Z","shell.execute_reply.started":"2023-04-30T14:06:09.687089Z","shell.execute_reply":"2023-04-30T14:06:09.694724Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"[Landmark(x=0.0001354031264781952, y=-0.05638786405324936, z=0.04831307753920555, visibility=0.0, presence=0.0),\n Landmark(x=-0.0204472579061985, y=-0.037365399301052094, z=0.03306834399700165, visibility=0.0, presence=0.0),\n Landmark(x=-0.0306948684155941, y=-0.017398076131939888, z=0.02088986150920391, visibility=0.0, presence=0.0),\n Landmark(x=-0.030556248500943184, y=-0.0009477399289608002, z=0.0052291275933384895, visibility=0.0, presence=0.0),\n Landmark(x=-0.03075431101024151, y=0.012153667397797108, z=-0.010694650001823902, visibility=0.0, presence=0.0),\n Landmark(x=-0.006494888570159674, y=0.002032971242442727, z=-0.00828457996249199, visibility=0.0, presence=0.0),\n Landmark(x=-0.015183228999376297, y=0.014901095069944859, z=-0.011591515503823757, visibility=0.0, presence=0.0),\n Landmark(x=-0.027484090998768806, y=0.034071020781993866, z=0.003978711552917957, visibility=0.0, presence=0.0),\n Landmark(x=-0.03781049698591232, y=0.047738999128341675, z=0.019584709778428078, visibility=0.0, presence=0.0),\n Landmark(x=0.001892321859486401, y=0.0008347670664079487, z=-0.003003905527293682, visibility=0.0, presence=0.0),\n Landmark(x=-0.0007222611457109451, y=0.021319257095456123, z=-0.004532496444880962, visibility=0.0, presence=0.0),\n Landmark(x=-0.010737475007772446, y=0.04125937074422836, z=0.01365724392235279, visibility=0.0, presence=0.0),\n Landmark(x=-0.02646825462579727, y=0.05725303664803505, z=0.03321485593914986, visibility=0.0, presence=0.0),\n Landmark(x=0.005321582779288292, y=0.0002934139920398593, z=0.004524284973740578, visibility=0.0, presence=0.0),\n Landmark(x=0.005880868993699551, y=0.01535433903336525, z=0.009798540733754635, visibility=0.0, presence=0.0),\n Landmark(x=-0.0016303854063153267, y=0.034180574119091034, z=0.02474578656256199, visibility=0.0, presence=0.0),\n Landmark(x=-0.0163614209741354, y=0.046236373484134674, z=0.042154647409915924, visibility=0.0, presence=0.0),\n Landmark(x=0.010867711156606674, y=-0.004789487458765507, z=0.0204328540712595, visibility=0.0, presence=0.0),\n Landmark(x=0.013241663575172424, y=0.00684369495138526, z=0.024176031351089478, visibility=0.0, presence=0.0),\n Landmark(x=0.010124018415808678, y=0.020132964476943016, z=0.03319269046187401, visibility=0.0, presence=0.0),\n Landmark(x=-0.0008873594924807549, y=0.027617450803518295, z=0.040588073432445526, visibility=0.0, presence=0.0)]"},"metadata":{}}]}]}